# The Planeswalker Agent - Environment Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# LLM PROVIDER CONFIGURATION
# =============================================================================
# Choose which LLM provider to use for response synthesis
# Options: "none", "openai", "openai_realtime", "anthropic", "auto"
#   - none: Use template-based responses (no API calls)
#   - openai: Use OpenAI Chat API (gpt-4o)
#   - openai_realtime: Use OpenAI Realtime API (WebSocket)
#   - anthropic: Use Anthropic Claude API
#   - auto: Auto-detect based on available API keys
LLM_PROVIDER=none

# =============================================================================
# OPENAI CONFIGURATION
# =============================================================================
# Your OpenAI API key (required for openai/openai_realtime providers)
OPENAI_API_KEY=

# --- Standard Chat API Settings ---
# API endpoint (default: https://api.openai.com/v1)
# OPENAI_API_ENDPOINT=https://api.openai.com/v1

# Model for Chat API (default: gpt-4o)
# OPENAI_CHAT_MODEL=gpt-4o

# --- Realtime API Settings ---
# Full WebSocket URL for Realtime API (optional - auto-built if not set)
# For OpenAI: wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview
# For Azure: wss://your-resource.openai.azure.com/openai/realtime?deployment=gpt-realtime
OPENAI_REALTIME_ENDPOINT=

# Realtime model name (default: gpt-4o-realtime-preview)
OPENAI_REALTIME_MODEL=gpt-4o-realtime-preview

# API version for Realtime API (default: 2024-10-01-preview)
OPENAI_REALTIME_API_VERSION=2024-10-01-preview

# --- Azure OpenAI Settings ---
# If using Azure OpenAI, set these instead of OPENAI_REALTIME_ENDPOINT
# Azure resource endpoint (e.g., https://your-resource.openai.azure.com)
# AZURE_OPENAI_ENDPOINT=

# Azure deployment name (e.g., gpt-realtime)
# AZURE_OPENAI_DEPLOYMENT=gpt-realtime

# --- LLM Parameters ---
# Temperature for response generation (0.0-2.0, default: 0.7)
# OPENAI_TEMPERATURE=0.7

# Maximum tokens in response (default: 2048)
# OPENAI_MAX_TOKENS=2048

# =============================================================================
# ANTHROPIC CONFIGURATION
# =============================================================================
# Your Anthropic API key (required for anthropic provider)
# ANTHROPIC_API_KEY=

# Model to use (default: claude-sonnet-4-20250514)
# ANTHROPIC_MODEL=claude-sonnet-4-20250514

# Temperature (default: 0.7)
# ANTHROPIC_TEMPERATURE=0.7

# Maximum tokens (default: 2048)
# ANTHROPIC_MAX_TOKENS=2048

# =============================================================================
# AGENT SETTINGS
# =============================================================================
# Enable verbose logging (true/false, default: false)
# VERBOSE=false

# Enable caching for external API calls (default: true)
# CACHE_ENABLED=true

# Cache directory (default: data)
# CACHE_DIR=data
