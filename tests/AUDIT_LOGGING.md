# Test Audit Logging

## Overview

All integration tests now include detailed audit logging that displays:
1. The query being tested
2. Expected data from external sources (EDHREC, MTGGoldfish, 17Lands, etc.)
3. Links to online sources for manual verification

## How to Use

When running tests with verbose output, you'll see detailed audit information for each test:

```bash
pytest tests/integration/ -v -s
```

The `-s` flag is important as it enables stdout capture, allowing you to see the audit logs.

## Audit Output Format

Each test will display output like this:

```
================================================================================
TEST AUDIT: Modern Metagame
================================================================================

QUERY:
  What are the top decks in Modern?

SOURCE URL (for manual audit):
  https://www.mtggoldfish.com/metagame/modern

EXPECTED DATA FROM SOURCE:
  source: MTGGoldfish Modern Metagame
  format: Modern
  top_decks:
    1. {'name': 'Izzet Murktide', 'percentage': '12.5%'}
    2. {'name': 'Amulet Titan', 'percentage': '9.8%'}
    3. {'name': 'Rakdos Scam', 'percentage': '8.3%'}
    ...

AGENT RESPONSE:
  The Modern metagame is currently dominated by Izzet Murktide, which makes up
  12.5% of the field. This deck leverages efficient counterspells and Dragon's
  Rage Channeler alongside the powerful Murktide Regent. Other top contenders
  include Amulet Titan at 9.8% and Rakdos Scam at 8.3%. The format remains
  diverse with multiple viable strategies.

================================================================================
```

The audit output now includes:
1. **Query**: The exact query being tested
2. **Source URL**: Direct link for manual verification
3. **Expected Data**: Data fetched from external sources
4. **Agent Response**: The actual response generated by the Planeswalker Agent

## What Gets Logged

### Commander Tests
- **Synergy Queries**: EDHREC commander pages with top synergy cards
- **Commander Recommendations**: Theme pages with expected commanders
- **Trending**: EDHREC weekly top commanders

**Source URLs**: EDHREC commander and theme pages

### Constructed Metagame Tests
- **Modern/Standard/Pioneer**: Current metagame percentages
- Top 5 decks with their meta share

**Source URLs**: MTGGoldfish metagame pages

### Limited/Draft Tests
- **Color Pairs**: 17Lands win rates by color combination
- **Archetypes**: Best performing draft strategies
- **Sealed**: Strategic guidance links

**Source URLs**: 17Lands color ratings and card ratings pages

### Synergy Tests
- **Card Synergies**: Local synergy graph data with scores
- **Theme Synergies**: EDHREC theme pages (Aristocrats, Graveyard, etc.)

**Source URLs**: EDHREC theme pages + local synergy data

### Semantic Search Tests
- **Card Search**: Vector store semantic search results
- **Mechanic Search**: Scryfall searches for verification

**Source URLs**: Scryfall search URLs + vector store data

## Manual Auditing

To manually audit a test result:

1. Run the test and note the SOURCE URL from the audit output
2. Visit the URL in your browser
3. Compare the expected data (from the audit log) with what you see on the website
4. **Review the AGENT RESPONSE** and verify it aligns with both:
   - The expected data shown in the audit log
   - The current online data from the source URL
5. Check if the agent mentioned the expected cards, commanders, or strategies

This is especially useful when:
- A test fails unexpectedly
- The metagame has shifted significantly
- You want to verify data freshness
- Debugging test assertions
- Evaluating response quality and accuracy

## Example Audit Workflow

```bash
# Run a specific test with audit logging
pytest tests/integration/test_commander.py::TestCommanderQueries::test_commander_synergy_atraxa -v -s

# Review the audit output showing:
# - Query: "What cards work well with Atraxa, Praetors' Voice?"
# - Source: https://edhrec.com/commanders/atraxa-praetors-voice
# - Expected top cards: [Tekuthal, Evolution Sage, Karn's Bastion, ...]
# - Agent Response: [The actual response generated by your agent]

# Visit the source URL to verify the data is current
# Compare agent response to expected data
# Verify the agent mentioned relevant cards and strategies
```

### What to Check in Agent Response

When reviewing the agent response, verify:
- **Accuracy**: Does it mention cards/decks from the expected data?
- **Relevance**: Does it answer the query appropriately?
- **Completeness**: Does it provide enough detail?
- **Currency**: Is the information up-to-date with the source?
- **Quality**: Is the explanation clear and helpful?

## Notes

- Audit data is fetched at test runtime from live sources when possible
- Some tests use static data (e.g., known card lists) as fallbacks
- URLs provided are for manual verification and may require additional navigation
- Expected data is limited to top 10 results for readability
